{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7daa8e72-fdee-4c6c-bb4c-79ceb747f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "#from rclpy.serialization import deserialize_message\n",
    "#import rosbag2_py\n",
    "from rosbag2_py import SequentialReader, StorageOptions, ConverterOptions\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "import os\n",
    "import sensor_msgs.msg\n",
    "import rosbag2_py\n",
    "from monoloco.predict import predict\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b8e687-420d-4bab-a820-6b0caa937b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youssefelsaady/miniforge3/envs/ros_env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f64dcd-aee2-4722-93bf-9448325be2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1742993691.523596004] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_0.db3' for READ_ONLY.\n"
     ]
    }
   ],
   "source": [
    "rosbag_path = \"/Users/youssefelsaady/Desktop/Practical Work/Optipex\"\n",
    "\n",
    "# Proceessing time\n",
    "start_time = 1734616775.774053335\n",
    "end_time = 1734616788.527853489\n",
    "\n",
    "# extracted images\n",
    "output_folder = \"extracted_images\"\n",
    "os.makedirs(output_folder , exist_ok = True)\n",
    "\n",
    "# Initializing ros_bag reader\n",
    "reader = SequentialReader()\n",
    "storage_options = StorageOptions(uri = rosbag_path , storage_id = 'sqlite3')\n",
    "converter_options = ConverterOptions('', '')\n",
    "reader.open(storage_options , converter_options)\n",
    "filter = rosbag2_py.StorageFilter(topics=[\"/zed/zed_node/left/image_rect_color\"])\n",
    "reader.set_filter(filter)\n",
    "# Geting topic information\n",
    "topics = reader.get_all_topics_and_types()\n",
    "bridge = CvBridge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05844a54-7333-40aa-ac33-baf8699d19af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1742918415.321099763] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_1.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: extracted_images/1734616775.774053335.png\n",
      "Saved: extracted_images/1734616775.940945387.png\n",
      "Saved: extracted_images/1734616776.074943542.png\n",
      "Saved: extracted_images/1734616776.207899332.png\n",
      "Saved: extracted_images/1734616776.374941349.png\n",
      "Saved: extracted_images/1734616776.508472443.png\n",
      "Saved: extracted_images/1734616776.642311335.png\n",
      "Saved: extracted_images/1734616776.775894403.png\n",
      "Saved: extracted_images/1734616776.942249537.png\n",
      "Saved: extracted_images/1734616777.076903343.png\n",
      "Saved: extracted_images/1734616777.242648363.png\n",
      "Saved: extracted_images/1734616777.410064459.png\n",
      "Saved: extracted_images/1734616777.543611526.png\n",
      "Saved: extracted_images/1734616777.710915327.png\n",
      "Saved: extracted_images/1734616777.844017506.png\n",
      "Saved: extracted_images/1734616778.011349440.png\n",
      "Saved: extracted_images/1734616778.144856453.png\n",
      "Saved: extracted_images/1734616778.311420441.png\n",
      "Saved: extracted_images/1734616778.445024490.png\n",
      "Saved: extracted_images/1734616778.579141378.png\n",
      "Saved: extracted_images/1734616778.745402336.png\n",
      "Saved: extracted_images/1734616778.879242420.png\n",
      "Saved: extracted_images/1734616779.012540340.png\n",
      "Saved: extracted_images/1734616779.179404497.png\n",
      "Saved: extracted_images/1734616779.346384525.png\n",
      "Saved: extracted_images/1734616779.479885340.png\n",
      "Saved: extracted_images/1734616779.613517523.png\n",
      "Saved: extracted_images/1734616779.780920506.png\n",
      "Saved: extracted_images/1734616779.947765350.png\n",
      "Saved: extracted_images/1734616780.114912510.png\n",
      "Saved: extracted_images/1734616780.280752420.png\n",
      "Saved: extracted_images/1734616780.448274374.png\n",
      "Saved: extracted_images/1734616780.649172544.png\n",
      "Saved: extracted_images/1734616780.815389395.png\n",
      "Saved: extracted_images/1734616780.982817411.png\n",
      "Saved: extracted_images/1734616781.182485342.png\n",
      "Saved: extracted_images/1734616781.383016348.png\n",
      "Saved: extracted_images/1734616781.516531467.png\n",
      "Saved: extracted_images/1734616781.683503389.png\n",
      "Saved: extracted_images/1734616781.883795500.png\n",
      "Saved: extracted_images/1734616782.050726414.png\n",
      "Saved: extracted_images/1734616782.217726469.png\n",
      "Saved: extracted_images/1734616782.418046474.png\n",
      "Saved: extracted_images/1734616782.584980488.png\n",
      "Saved: extracted_images/1734616782.786443472.png\n",
      "Saved: extracted_images/1734616782.952224493.png\n",
      "Saved: extracted_images/1734616783.152488470.png\n",
      "Saved: extracted_images/1734616783.319726467.png\n",
      "Saved: extracted_images/1734616783.519718409.png\n",
      "Saved: extracted_images/1734616783.686670542.png\n",
      "Saved: extracted_images/1734616783.887075424.png\n",
      "Saved: extracted_images/1734616784.054267406.png\n",
      "Saved: extracted_images/1734616784.220544338.png\n",
      "Saved: extracted_images/1734616784.388057470.png\n",
      "Saved: extracted_images/1734616784.555142403.png\n",
      "Saved: extracted_images/1734616784.721693516.png\n",
      "Saved: extracted_images/1734616784.922120333.png\n",
      "Saved: extracted_images/1734616785.088638544.png\n",
      "Saved: extracted_images/1734616785.289476395.png\n",
      "Saved: extracted_images/1734616785.456094503.png\n",
      "Saved: extracted_images/1734616785.623207331.png\n",
      "Saved: extracted_images/1734616785.823025465.png\n",
      "Saved: extracted_images/1734616785.990007401.png\n",
      "Saved: extracted_images/1734616786.157559395.png\n",
      "Saved: extracted_images/1734616786.290850401.png\n",
      "Saved: extracted_images/1734616786.457945347.png\n",
      "Saved: extracted_images/1734616786.558060408.png\n",
      "Saved: extracted_images/1734616786.724496365.png\n",
      "Saved: extracted_images/1734616786.858587503.png\n",
      "Saved: extracted_images/1734616787.025492430.png\n",
      "Saved: extracted_images/1734616787.158945560.png\n",
      "Saved: extracted_images/1734616787.326381445.png\n",
      "Saved: extracted_images/1734616787.459607363.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1742918415.984827935] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_2.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: extracted_images/1734616787.626941442.png\n",
      "Saved: extracted_images/1734616787.760415554.png\n",
      "Saved: extracted_images/1734616787.927043438.png\n",
      "Saved: extracted_images/1734616788.060040474.png\n",
      "Saved: extracted_images/1734616788.228708506.png\n",
      "Saved: extracted_images/1734616788.394329548.png\n",
      "Saved: extracted_images/1734616788.527853489.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1742918416.353442234] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_3.db3' for READ_ONLY.\n",
      "[INFO] [1742918416.549804301] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_4.db3' for READ_ONLY.\n",
      "[INFO] [1742918416.732991507] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_5.db3' for READ_ONLY.\n",
      "[INFO] [1742918416.916260421] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_6.db3' for READ_ONLY.\n",
      "[INFO] [1742918417.110215808] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_7.db3' for READ_ONLY.\n",
      "[INFO] [1742918417.305631620] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_8.db3' for READ_ONLY.\n",
      "[INFO] [1742918417.493407559] [rosbag2_storage]: Opened database '/Users/youssefelsaady/Desktop/Practical Work/Optipex/005_sabry_9.db3' for READ_ONLY.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error reading SQL query. SQLite error (11): database disk image is malformed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read messages from the bag\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#reader.set_filter([(\"/zed/zed_node/left/image_rect_color\", \"sensor_msgs/msg/Image\")])\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m reader.has_next():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     topic, data, timestamp = \u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     msg = deserialize_message(data, sensor_msgs.msg.Image)\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Convert ROS2 timestamp to seconds\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Error reading SQL query. SQLite error (11): database disk image is malformed"
     ]
    }
   ],
   "source": [
    "# Reading the messages from the ros_bag\n",
    "#reader.set_filter([(\"/zed/zed_node/left/image_rect_color\", \"sensor_msgs/msg/Image\")])\n",
    "while reader.has_next():\n",
    "    topic , data , timestamp = reader.read_next()\n",
    "    msg = deserialize_message(data , sensor_msgs.msg.Image)\n",
    "    # converting ros timestamp to seconds\n",
    "    msg_time = msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9\n",
    "    # Making sure the message is within the time range we need\n",
    "    if start_time <= msg_time <= end_time:\n",
    "        # converting Ros2 image to opencv format\n",
    "        cv_image = bridge.imgmsg_to_cv2(msg , desired_encoding = \"bgr8\")\n",
    "        # saveing the image as a PNG file\n",
    "        image_filename = os.path.join(output_folder , f\"{msg_time:.9f}.png\")\n",
    "        cv2.imwrite(image_filename , cv_image)\n",
    "        print(f\"Saved: {image_filename}\")\n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8eccf0-d46b-425d-8b9b-c228bd0caa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 1734616787.927043438.png: name 'predict' is not defined\n",
      "Error processing 1734616785.289476395.png: name 'predict' is not defined\n",
      "Error processing 1734616779.947765350.png: name 'predict' is not defined\n",
      "Error processing 1734616778.879242420.png: name 'predict' is not defined\n",
      "Error processing 1734616783.686670542.png: name 'predict' is not defined\n",
      "Error processing 1734616786.457945347.png: name 'predict' is not defined\n",
      "Error processing 1734616786.724496365.png: name 'predict' is not defined\n",
      "Error processing 1734616786.558060408.png: name 'predict' is not defined\n",
      "Error processing 1734616783.887075424.png: name 'predict' is not defined\n",
      "Error processing 1734616778.011349440.png: name 'predict' is not defined\n",
      "Error processing 1734616785.456094503.png: name 'predict' is not defined\n",
      "Error processing 1734616780.114912510.png: name 'predict' is not defined\n",
      "Error processing 1734616780.815389395.png: name 'predict' is not defined\n",
      "Error processing 1734616781.883795500.png: name 'predict' is not defined\n",
      "Error processing 1734616778.745402336.png: name 'predict' is not defined\n",
      "Error processing 1734616783.319726467.png: name 'predict' is not defined\n",
      "Error processing 1734616784.721693516.png: name 'predict' is not defined\n",
      "Error processing 1734616787.626941442.png: name 'predict' is not defined\n",
      "Error processing 1734616784.054267406.png: name 'predict' is not defined\n",
      "Error processing 1734616776.775894403.png: name 'predict' is not defined\n",
      "Error processing 1734616782.952224493.png: name 'predict' is not defined\n",
      "Error processing 1734616782.217726469.png: name 'predict' is not defined\n",
      "Error processing 1734616786.157559395.png: name 'predict' is not defined\n",
      "Error processing 1734616779.179404497.png: name 'predict' is not defined\n",
      "Error processing 1734616778.311420441.png: name 'predict' is not defined\n",
      "Error processing 1734616776.074943542.png: name 'predict' is not defined\n",
      "Error processing 1734616784.555142403.png: name 'predict' is not defined\n",
      "Error processing 1734616781.182485342.png: name 'predict' is not defined\n",
      "Error processing 1734616777.242648363.png: name 'predict' is not defined\n",
      "Error processing 1734616781.683503389.png: name 'predict' is not defined\n",
      "Error processing 1734616788.527853489.png: name 'predict' is not defined\n",
      "Error processing 1734616781.383016348.png: name 'predict' is not defined\n",
      "Error processing 1734616780.649172544.png: name 'predict' is not defined\n",
      "Error processing 1734616781.516531467.png: name 'predict' is not defined\n",
      "Error processing 1734616776.642311335.png: name 'predict' is not defined\n",
      "Error processing 1734616775.940945387.png: name 'predict' is not defined\n",
      "Error processing 1734616775.774053335.png: name 'predict' is not defined\n",
      "Error processing 1734616779.780920506.png: name 'predict' is not defined\n",
      "Error processing 1734616777.543611526.png: name 'predict' is not defined\n",
      "Error processing 1734616777.844017506.png: name 'predict' is not defined\n",
      "Error processing 1734616785.823025465.png: name 'predict' is not defined\n",
      "Error processing 1734616784.922120333.png: name 'predict' is not defined\n",
      "Error processing 1734616785.623207331.png: name 'predict' is not defined\n",
      "Error processing 1734616788.394329548.png: name 'predict' is not defined\n",
      "Error processing 1734616780.982817411.png: name 'predict' is not defined\n",
      "Error processing 1734616787.158945560.png: name 'predict' is not defined\n",
      "Error processing 1734616779.613517523.png: name 'predict' is not defined\n",
      "Error processing 1734616783.152488470.png: name 'predict' is not defined\n",
      "Error processing 1734616786.290850401.png: name 'predict' is not defined\n",
      "Error processing 1734616779.346384525.png: name 'predict' is not defined\n",
      "Error processing 1734616778.579141378.png: name 'predict' is not defined\n",
      "Error processing 1734616776.942249537.png: name 'predict' is not defined\n",
      "Error processing 1734616782.418046474.png: name 'predict' is not defined\n",
      "Error processing 1734616786.858587503.png: name 'predict' is not defined\n",
      "Error processing 1734616787.760415554.png: name 'predict' is not defined\n",
      "Error processing 1734616784.388057470.png: name 'predict' is not defined\n",
      "Error processing 1734616776.508472443.png: name 'predict' is not defined\n",
      "Error processing 1734616778.445024490.png: name 'predict' is not defined\n",
      "Error processing 1734616788.060040474.png: name 'predict' is not defined\n",
      "Error processing 1734616782.786443472.png: name 'predict' is not defined\n",
      "Error processing 1734616783.519718409.png: name 'predict' is not defined\n",
      "Error processing 1734616787.025492430.png: name 'predict' is not defined\n",
      "Error processing 1734616785.088638544.png: name 'predict' is not defined\n",
      "Error processing 1734616787.326381445.png: name 'predict' is not defined\n",
      "Error processing 1734616780.280752420.png: name 'predict' is not defined\n",
      "Error processing 1734616778.144856453.png: name 'predict' is not defined\n",
      "Error processing 1734616777.076903343.png: name 'predict' is not defined\n",
      "Error processing 1734616777.710915327.png: name 'predict' is not defined\n",
      "Error processing 1734616779.012540340.png: name 'predict' is not defined\n",
      "Error processing 1734616779.479885340.png: name 'predict' is not defined\n",
      "Error processing 1734616780.448274374.png: name 'predict' is not defined\n",
      "Error processing 1734616782.050726414.png: name 'predict' is not defined\n",
      "Error processing 1734616776.374941349.png: name 'predict' is not defined\n",
      "Error processing 1734616785.990007401.png: name 'predict' is not defined\n",
      "Error processing 1734616776.207899332.png: name 'predict' is not defined\n",
      "Error processing 1734616784.220544338.png: name 'predict' is not defined\n",
      "Error processing 1734616788.228708506.png: name 'predict' is not defined\n",
      "Error processing 1734616787.459607363.png: name 'predict' is not defined\n",
      "Error processing 1734616777.410064459.png: name 'predict' is not defined\n",
      "Error processing 1734616782.584980488.png: name 'predict' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "image_dir = '/Users/youssefelsaady/Desktop/Practical Work/extracted_images/'  \n",
    "output_dir = '/Users/youssefelsaady/Desktop/Practical Work/output_predictions/' \n",
    "os.makedirs(output_dir , exist_ok = True)\n",
    "# Initializing the Monoloco model\n",
    "#model = MonolocoModel()\n",
    "# looping through the images & runing the model\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # doing the full image path\n",
    "        image_path = os.path.join(image_dir , filename)\n",
    "        # creating the output path for prediction\n",
    "        output_path = os.path.join(output_dir , filename.split('.')[0])\n",
    "        try:\n",
    "            predict(\n",
    "                image_path, \n",
    "                mode='mono',  \n",
    "                output_dir = output_path, \n",
    "                long_edge = 1000 \n",
    "            )\n",
    "            print(f\"Processed: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904a522d-28e7-4ea0-8db1-458cc7542116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing image: 1734616787.927043438.png\n",
      "ERROR:root:Error processing 1734616787.927043438.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616785.289476395.png\n",
      "ERROR:root:Error processing 1734616785.289476395.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.947765350.png\n",
      "ERROR:root:Error processing 1734616779.947765350.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.879242420.png\n",
      "ERROR:root:Error processing 1734616778.879242420.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616783.686670542.png\n",
      "ERROR:root:Error processing 1734616783.686670542.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616786.457945347.png\n",
      "ERROR:root:Error processing 1734616786.457945347.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616786.724496365.png\n",
      "ERROR:root:Error processing 1734616786.724496365.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616786.558060408.png\n",
      "ERROR:root:Error processing 1734616786.558060408.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616783.887075424.png\n",
      "ERROR:root:Error processing 1734616783.887075424.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.011349440.png\n",
      "ERROR:root:Error processing 1734616778.011349440.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616785.456094503.png\n",
      "ERROR:root:Error processing 1734616785.456094503.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616780.114912510.png\n",
      "ERROR:root:Error processing 1734616780.114912510.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616780.815389395.png\n",
      "ERROR:root:Error processing 1734616780.815389395.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616781.883795500.png\n",
      "ERROR:root:Error processing 1734616781.883795500.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.745402336.png\n",
      "ERROR:root:Error processing 1734616778.745402336.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616783.319726467.png\n",
      "ERROR:root:Error processing 1734616783.319726467.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616784.721693516.png\n",
      "ERROR:root:Error processing 1734616784.721693516.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616787.626941442.png\n",
      "ERROR:root:Error processing 1734616787.626941442.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616784.054267406.png\n",
      "ERROR:root:Error processing 1734616784.054267406.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.775894403.png\n",
      "ERROR:root:Error processing 1734616776.775894403.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616782.952224493.png\n",
      "ERROR:root:Error processing 1734616782.952224493.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616782.217726469.png\n",
      "ERROR:root:Error processing 1734616782.217726469.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616786.157559395.png\n",
      "ERROR:root:Error processing 1734616786.157559395.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.179404497.png\n",
      "ERROR:root:Error processing 1734616779.179404497.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.311420441.png\n",
      "ERROR:root:Error processing 1734616778.311420441.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.074943542.png\n",
      "ERROR:root:Error processing 1734616776.074943542.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616784.555142403.png\n",
      "ERROR:root:Error processing 1734616784.555142403.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616781.182485342.png\n",
      "ERROR:root:Error processing 1734616781.182485342.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616777.242648363.png\n",
      "ERROR:root:Error processing 1734616777.242648363.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616781.683503389.png\n",
      "ERROR:root:Error processing 1734616781.683503389.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616788.527853489.png\n",
      "ERROR:root:Error processing 1734616788.527853489.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616781.383016348.png\n",
      "ERROR:root:Error processing 1734616781.383016348.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616780.649172544.png\n",
      "ERROR:root:Error processing 1734616780.649172544.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616781.516531467.png\n",
      "ERROR:root:Error processing 1734616781.516531467.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.642311335.png\n",
      "ERROR:root:Error processing 1734616776.642311335.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616775.940945387.png\n",
      "ERROR:root:Error processing 1734616775.940945387.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616775.774053335.png\n",
      "ERROR:root:Error processing 1734616775.774053335.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.780920506.png\n",
      "ERROR:root:Error processing 1734616779.780920506.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616777.543611526.png\n",
      "ERROR:root:Error processing 1734616777.543611526.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616777.844017506.png\n",
      "ERROR:root:Error processing 1734616777.844017506.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616785.823025465.png\n",
      "ERROR:root:Error processing 1734616785.823025465.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616784.922120333.png\n",
      "ERROR:root:Error processing 1734616784.922120333.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616785.623207331.png\n",
      "ERROR:root:Error processing 1734616785.623207331.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616788.394329548.png\n",
      "ERROR:root:Error processing 1734616788.394329548.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616780.982817411.png\n",
      "ERROR:root:Error processing 1734616780.982817411.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616787.158945560.png\n",
      "ERROR:root:Error processing 1734616787.158945560.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.613517523.png\n",
      "ERROR:root:Error processing 1734616779.613517523.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616783.152488470.png\n",
      "ERROR:root:Error processing 1734616783.152488470.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616786.290850401.png\n",
      "ERROR:root:Error processing 1734616786.290850401.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.346384525.png\n",
      "ERROR:root:Error processing 1734616779.346384525.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.579141378.png\n",
      "ERROR:root:Error processing 1734616778.579141378.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.942249537.png\n",
      "ERROR:root:Error processing 1734616776.942249537.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616782.418046474.png\n",
      "ERROR:root:Error processing 1734616782.418046474.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616786.858587503.png\n",
      "ERROR:root:Error processing 1734616786.858587503.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616787.760415554.png\n",
      "ERROR:root:Error processing 1734616787.760415554.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616784.388057470.png\n",
      "ERROR:root:Error processing 1734616784.388057470.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.508472443.png\n",
      "ERROR:root:Error processing 1734616776.508472443.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.445024490.png\n",
      "ERROR:root:Error processing 1734616778.445024490.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616788.060040474.png\n",
      "ERROR:root:Error processing 1734616788.060040474.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616782.786443472.png\n",
      "ERROR:root:Error processing 1734616782.786443472.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616783.519718409.png\n",
      "ERROR:root:Error processing 1734616783.519718409.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616787.025492430.png\n",
      "ERROR:root:Error processing 1734616787.025492430.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616785.088638544.png\n",
      "ERROR:root:Error processing 1734616785.088638544.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616787.326381445.png\n",
      "ERROR:root:Error processing 1734616787.326381445.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616780.280752420.png\n",
      "ERROR:root:Error processing 1734616780.280752420.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616778.144856453.png\n",
      "ERROR:root:Error processing 1734616778.144856453.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616777.076903343.png\n",
      "ERROR:root:Error processing 1734616777.076903343.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616777.710915327.png\n",
      "ERROR:root:Error processing 1734616777.710915327.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.012540340.png\n",
      "ERROR:root:Error processing 1734616779.012540340.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616779.479885340.png\n",
      "ERROR:root:Error processing 1734616779.479885340.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616780.448274374.png\n",
      "ERROR:root:Error processing 1734616780.448274374.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616782.050726414.png\n",
      "ERROR:root:Error processing 1734616782.050726414.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.374941349.png\n",
      "ERROR:root:Error processing 1734616776.374941349.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616785.990007401.png\n",
      "ERROR:root:Error processing 1734616785.990007401.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616776.207899332.png\n",
      "ERROR:root:Error processing 1734616776.207899332.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616784.220544338.png\n",
      "ERROR:root:Error processing 1734616784.220544338.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616788.228708506.png\n",
      "ERROR:root:Error processing 1734616788.228708506.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616787.459607363.png\n",
      "ERROR:root:Error processing 1734616787.459607363.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616777.410064459.png\n",
      "ERROR:root:Error processing 1734616777.410064459.png: name 'predict' is not defined\n",
      "INFO:root:Processing image: 1734616782.584980488.png\n",
      "ERROR:root:Error processing 1734616782.584980488.png: name 'predict' is not defined\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import monoloco.run\n",
    "import logging\n",
    "\n",
    "# Trying logging \n",
    "logging.basicConfig(level = logging.INFO)\n",
    "# Paths\n",
    "image_dir = '/Users/youssefelsaady/Desktop/Practical Work/extracted_images/'  \n",
    "output_dir = '/Users/youssefelsaady/Desktop/Practical Work/output_predictions/'  \n",
    "os.makedirs(output_dir , exist_ok = True)\n",
    "# looping through the images & runing the model\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # doing the full image path\n",
    "        image_path = os.path.join(image_dir , filename)     \n",
    "        # creating the output path for prediction while saving the output with the same name but in output_dir\n",
    "        output_path = os.path.join(output_dir , filename.split('.')[0])\n",
    "        try:\n",
    "            logging.info(f\"Processing image: {filename}\")\n",
    "            predict(\n",
    "                image_path,  \n",
    "                mode='mono',  \n",
    "                output_directory = output_path,  \n",
    "                long_edge = 1000  \n",
    "            )\n",
    "            logging.info(f\"Processed: {filename}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e169c159-2154-4c10-9f72-776bc0c6db47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1734616787.927043438.png\n",
      "Processed: 1734616785.289476395.png\n",
      "Processed: 1734616779.947765350.png\n",
      "Processed: 1734616778.879242420.png\n",
      "Processed: 1734616783.686670542.png\n",
      "Processed: 1734616786.457945347.png\n",
      "Processed: 1734616786.724496365.png\n",
      "Processed: 1734616786.558060408.png\n",
      "Processed: 1734616783.887075424.png\n",
      "Processed: 1734616778.011349440.png\n",
      "Processed: 1734616785.456094503.png\n",
      "Processed: 1734616780.114912510.png\n",
      "Processed: 1734616780.815389395.png\n",
      "Processed: 1734616781.883795500.png\n",
      "Processed: 1734616778.745402336.png\n",
      "Processed: 1734616783.319726467.png\n",
      "Processed: 1734616784.721693516.png\n",
      "Processed: 1734616787.626941442.png\n",
      "Processed: 1734616784.054267406.png\n",
      "Processed: 1734616776.775894403.png\n",
      "Processed: 1734616782.952224493.png\n",
      "Processed: 1734616782.217726469.png\n",
      "Processed: 1734616786.157559395.png\n",
      "Processed: 1734616779.179404497.png\n",
      "Processed: 1734616778.311420441.png\n",
      "Processed: 1734616776.074943542.png\n",
      "Processed: 1734616784.555142403.png\n",
      "Processed: 1734616781.182485342.png\n",
      "Processed: 1734616777.242648363.png\n",
      "Processed: 1734616781.683503389.png\n",
      "Processed: 1734616788.527853489.png\n",
      "Processed: 1734616781.383016348.png\n",
      "Processed: 1734616780.649172544.png\n",
      "Processed: 1734616781.516531467.png\n",
      "Processed: 1734616776.642311335.png\n",
      "Processed: 1734616775.940945387.png\n",
      "Processed: 1734616775.774053335.png\n",
      "Processed: 1734616779.780920506.png\n",
      "Processed: 1734616777.543611526.png\n",
      "Processed: 1734616777.844017506.png\n",
      "Processed: 1734616785.823025465.png\n",
      "Processed: 1734616784.922120333.png\n",
      "Processed: 1734616785.623207331.png\n",
      "Processed: 1734616788.394329548.png\n",
      "Processed: 1734616780.982817411.png\n",
      "Processed: 1734616787.158945560.png\n",
      "Processed: 1734616779.613517523.png\n",
      "Processed: 1734616783.152488470.png\n",
      "Processed: 1734616786.290850401.png\n",
      "Processed: 1734616779.346384525.png\n",
      "Processed: 1734616778.579141378.png\n",
      "Processed: 1734616776.942249537.png\n",
      "Processed: 1734616782.418046474.png\n",
      "Processed: 1734616786.858587503.png\n",
      "Processed: 1734616787.760415554.png\n",
      "Processed: 1734616784.388057470.png\n",
      "Processed: 1734616776.508472443.png\n",
      "Processed: 1734616778.445024490.png\n",
      "Processed: 1734616788.060040474.png\n",
      "Processed: 1734616782.786443472.png\n",
      "Processed: 1734616783.519718409.png\n",
      "Processed: 1734616787.025492430.png\n",
      "Processed: 1734616785.088638544.png\n",
      "Processed: 1734616787.326381445.png\n",
      "Processed: 1734616780.280752420.png\n",
      "Processed: 1734616778.144856453.png\n",
      "Processed: 1734616777.076903343.png\n",
      "Processed: 1734616777.710915327.png\n",
      "Processed: 1734616779.012540340.png\n",
      "Processed: 1734616779.479885340.png\n",
      "Processed: 1734616780.448274374.png\n",
      "Processed: 1734616782.050726414.png\n",
      "Processed: 1734616776.374941349.png\n",
      "Processed: 1734616785.990007401.png\n",
      "Processed: 1734616776.207899332.png\n",
      "Processed: 1734616784.220544338.png\n",
      "Processed: 1734616788.228708506.png\n",
      "Processed: 1734616787.459607363.png\n",
      "Processed: 1734616777.410064459.png\n",
      "Processed: 1734616782.584980488.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "image_dir = '/Users/youssefelsaady/Desktop/Practical work/extracted_images/'\n",
    "output_dir = '/Users/youssefelsaady/Desktop/Practical work/output_predictions/'\n",
    "os.makedirs(output_dir , exist_ok = True)\n",
    "# looping through the images & runing the model\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # doing the full image path\n",
    "        image_path = os.path.join(image_dir , filename)\n",
    "        # creating the output path for prediction\n",
    "        output_path = os.path.join(output_dir , f\"out_{filename}\")\n",
    "        # runing model in shell\n",
    "        command = [\n",
    "            \"python3\", \"-m\", \"monoloco.run\", \"predict\", \n",
    "            image_path, \n",
    "            \"--output-directory\", output_dir \n",
    "        ]\n",
    "        try:\n",
    "            result = subprocess.run(command, capture_output=True, text=True)\n",
    "            # Check for any errors in the command output\n",
    "            if result.returncode == 0:\n",
    "                print(f\"Processed: {filename}\")\n",
    "            else:\n",
    "                print(f\"Error processing {filename}: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command for {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ef1ee1-64e0-4f40-b651-dd7551f2adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 1734616787.927043438.png: INFO:monoloco.predict:Force complete pose is active\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 150, in main\n",
      "    predict(args)\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/predict.py\", line 166, in predict\n",
      "    net = Loco(\n",
      "          ^^^^^\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/network/net.py\", line 77, in __init__\n",
      "    self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1028, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1246, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: unpickling stack underflow\n",
      "\n",
      "Error processing 1734616785.289476395.png: INFO:monoloco.predict:Force complete pose is active\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 150, in main\n",
      "    predict(args)\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/predict.py\", line 166, in predict\n",
      "    net = Loco(\n",
      "          ^^^^^\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/network/net.py\", line 77, in __init__\n",
      "    self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1028, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1246, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: unpickling stack underflow\n",
      "\n",
      "Error processing 1734616779.947765350.png: INFO:monoloco.predict:Force complete pose is active\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 150, in main\n",
      "    predict(args)\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/predict.py\", line 166, in predict\n",
      "    net = Loco(\n",
      "          ^^^^^\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/network/net.py\", line 77, in __init__\n",
      "    self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1028, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1246, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: unpickling stack underflow\n",
      "\n",
      "Error processing 1734616778.879242420.png: INFO:monoloco.predict:Force complete pose is active\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 150, in main\n",
      "    predict(args)\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/predict.py\", line 166, in predict\n",
      "    net = Loco(\n",
      "          ^^^^^\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/network/net.py\", line 77, in __init__\n",
      "    self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1028, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1246, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: unpickling stack underflow\n",
      "\n",
      "Error processing 1734616783.686670542.png: INFO:monoloco.predict:Force complete pose is active\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 150, in main\n",
      "    predict(args)\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/predict.py\", line 166, in predict\n",
      "    net = Loco(\n",
      "          ^^^^^\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/network/net.py\", line 77, in __init__\n",
      "    self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1028, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1246, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: unpickling stack underflow\n",
      "\n",
      "Error processing 1734616786.457945347.png: INFO:monoloco.predict:Force complete pose is active\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 221, in <module>\n",
      "    main()\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/run.py\", line 150, in main\n",
      "    predict(args)\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/predict.py\", line 166, in predict\n",
      "    net = Loco(\n",
      "          ^^^^^\n",
      "  File \"/Users/youssefelsaady/Desktop/Practical work/Monoloco/monoloco/network/net.py\", line 77, in __init__\n",
      "    self.model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1028, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/youssefelsaady/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py\", line 1246, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: unpickling stack underflow\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     17\u001b[39m command = [\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-m\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmonoloco.run\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     image_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m--output-directory\u001b[39m\u001b[33m\"\u001b[39m, output_dir   \u001b[38;5;66;03m# specifying the output folder\u001b[39;00m\n\u001b[32m     23\u001b[39m ]\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Check for any errors in the command output\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.returncode == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ros_env/lib/python3.11/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ros_env/lib/python3.11/subprocess.py:1209\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1206\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1211\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ros_env/lib/python3.11/subprocess.py:2113\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2106\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2107\u001b[39m                         stdout, stderr,\n\u001b[32m   2108\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2110\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2111\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2113\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2116\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2117\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ros_env/lib/python3.11/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28mself\u001b[39m._selector.poll(timeout)\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "image_dir = '/Users/youssefelsaady/Desktop/Practical work/extracted_images/'\n",
    "output_dir = '/Users/youssefelsaady/Desktop/Practical work/Output_of_trained_model/'\n",
    "model_path = \"/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pkl\"\n",
    "os.makedirs(output_dir , exist_ok = True)\n",
    "# looping through the images & runing the model\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # doing the full image path\n",
    "        image_path = os.path.join(image_dir , filename)\n",
    "        # creating the output path for prediction\n",
    "        output_path = os.path.join(output_dir , f\"out_{filename}\")\n",
    "        # runing model in shell\n",
    "        command = [\n",
    "            \"python3\", \"-m\", \"monoloco.run\", \"predict\",\n",
    "            image_path,\n",
    "            \"--mode\", \"mono\",                  # using mono mode\n",
    "            \"--model\", f\"{model_path}\",             # specifying the model path\n",
    "            \"--output-directory\", output_dir   # specifying the output folder\n",
    "        ]\n",
    "        try:\n",
    "            result = subprocess.run(command, capture_output=True, text=True)\n",
    "            # Check for any errors in the command output\n",
    "            if result.returncode == 0:\n",
    "                print(f\"Processed: {filename}\")\n",
    "            else:\n",
    "                print(f\"Error processing {filename}: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command for {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c16856-551d-43ad-98de-2b44d4f70781",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "unpickling stack underflow",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmonoloco\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnetwork\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Loco\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Initialize the model with the required parameters (assuming 'mono' mode is correct for your use case)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mLoco\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmono\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust 'model' with the correct parameter\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Optionally, load checkpoint if needed\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# model.load_state_dict(torch.load('<path_to_checkpoint>'))\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Save the model state dict after the training is complete\u001b[39;00m\n\u001b[32m     10\u001b[39m torch.save(model.state_dict(), \u001b[33m\"\u001b[39m\u001b[33m/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practical work/Monoloco/monoloco/network/net.py:77\u001b[39m, in \u001b[36mLoco.__init__\u001b[39m\u001b[34m(self, model, mode, net, device, n_dropout, p_dropout, linear_size)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     74\u001b[39m         \u001b[38;5;28mself\u001b[39m.model = LocoModel(p_dropout=p_dropout, input_size=input_size, output_size=output_size,\n\u001b[32m     75\u001b[39m                                     linear_size=linear_size, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py:1028\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1026\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1027\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(UNSAFE_MESSAGE + \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ros_env/lib/python3.11/site-packages/torch/serialization.py:1246\u001b[39m, in \u001b[36m_legacy_load\u001b[39m\u001b[34m(f, map_location, pickle_module, **pickle_load_args)\u001b[39m\n\u001b[32m   1240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[33m'\u001b[39m\u001b[33mreadinto\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[32m3\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m0\u001b[39m) <= sys.version_info < (\u001b[32m3\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m2\u001b[39m):\n\u001b[32m   1241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1242\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1243\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfunctionality.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m magic_number = \u001b[43mpickle_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic_number != MAGIC_NUMBER:\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid magic number; corrupt file?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mUnpicklingError\u001b[39m: unpickling stack underflow"
     ]
    }
   ],
   "source": [
    "from monoloco.network import Loco\n",
    "\n",
    "# Initialize the model with the required parameters (assuming 'mono' mode is correct for your use case)\n",
    "model = Loco(model='/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pkl', mode='mono')  # Adjust 'model' with the correct parameter\n",
    "\n",
    "# Optionally, load checkpoint if needed\n",
    "# model.load_state_dict(torch.load('<path_to_checkpoint>'))\n",
    "\n",
    "# Save the model state dict after the training is complete\n",
    "torch.save(model.state_dict(), \"/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "135b6719-31f3-4177-9499-9ee77fed21cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: /Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pkl\n",
      "Training failed: name 'train' is not defined\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monoloco.run   # Import the train function from monoloco.run\n",
    "\n",
    "# Manually define the arguments (as done in the terminal command)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.joints = \"/Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\"\n",
    "        self.mode = 'mono'\n",
    "        self.out = \"/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output.pkl\"  # Save model as .pkl\n",
    "        self.e = 50  # Epochs\n",
    "        self.bs = 8  # Batch size\n",
    "        self.monocular = True  # Use monocular mode\n",
    "        self.dropout = 0.2\n",
    "        self.lr = 0.001  # Learning rate\n",
    "        self.sched_step = 10  # Scheduler step\n",
    "        self.sched_gamma = 0.5  # Scheduler gamma\n",
    "        self.hidden_size = 512\n",
    "        self.n_stage = 3\n",
    "        self.print_loss = True  # Print loss\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")  # Set device\n",
    "        self.log_file = \"/Users/youssefelsaady/Desktop/Practical work/Train_output/training_log.txt\"  # Save log\n",
    "\n",
    "# Create the argument object\n",
    "args = Args()\n",
    "\n",
    "# Ensure the output model path is correct\n",
    "print(f\"Saving model to: {args.out}\")\n",
    "\n",
    "# Call the training function with the updated arguments\n",
    "try:\n",
    "    train(args)  # Call the train function from monoloco.run with the args object\n",
    "    print(f\"Training complete. Model saved to {args.out}\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0590306-6b6e-48d6-88cd-9035b433e1ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process completed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command as a list (same as your terminal command)\n",
    "command = [\n",
    "    \"python3\", \"-m\", \"monoloco.run\", \"train\",\n",
    "    \"--joints\", \"/Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\",\n",
    "    \"--mode\", \"mono\",\n",
    "    \"--out\", \"/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output2.pkl\",\n",
    "    \"-e\", \"50\",  # Epochs\n",
    "    \"--bs\", \"8\",  # Batch size\n",
    "    \"--monocular\",\n",
    "    \"--dropout\", \"0.2\",\n",
    "    \"--lr\", \"0.001\",\n",
    "    \"--sched_step\", \"10\",\n",
    "    \"--sched_gamma\", \"0.5\",\n",
    "    \"--hidden_size\", \"512\",\n",
    "    \"--n_stage\", \"3\",\n",
    "    \"--print_loss\",\n",
    "]\n",
    "\n",
    "# Add tee command to log output\n",
    "log_file = \"/Users/youssefelsaady/Desktop/Practical work/Train_output/training_log2.txt\"\n",
    "command += [\"|\", \"tee\", log_file]\n",
    "\n",
    "# Execute the command\n",
    "try:\n",
    "    result = subprocess.run(command, check=True, text=True, shell=True)\n",
    "    print(\"Training process completed.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2d1a6dc-e8a5-43ab-8325-11a9b01739fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_outputtrial.pkl\n",
      "Device:  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_outputtrial.pkl\n",
      ">>> creating model\n",
      ">>> model params: 8.458M\n",
      ">>> loss params: 7\n",
      "0 T::189.6  d:10507  x:4196  y:13093  h:4345  w:7929  l:4760  ori:49.0  V::185.2  d:10382  x:4113  y:12917  h:4295  w:7746  l:4703  ori:45.4  \n",
      "10 T::186.8  d:10434  x:4117  y:13014  h:4266  w:7849  l:4679  ori:47.8  V::186.1  d:10395  x:4140  y:12938  h:4311  w:7770  l:4727  ori:45.2  \n",
      "20 T::186.7  d:10431  x:4115  y:13011  h:4265  w:7848  l:4679  ori:47.9  V::186.0  d:10415  x:4144  y:12950  h:4327  w:7780  l:4736  ori:46.0  \n",
      "30 T::186.7  d:10434  x:4119  y:13014  h:4267  w:7850  l:4680  ori:47.9  V::185.1  d:10387  x:4107  y:12917  h:4296  w:7740  l:4697  ori:46.1  \n",
      "40 T::186.7  d:10433  x:4118  y:13014  h:4265  w:7849  l:4679  ori:47.8  V::186.4  d:10425  x:4159  y:12963  h:4338  w:7794  l:4751  ori:45.9  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Training:\n",
      "Training complete in 5m 2s\n",
      "Best training Accuracy: 186.686\n",
      "Best training Accuracy: 186.686\n",
      "Best training Accuracy: 186.686\n",
      "Best training Accuracy: 186.686\n",
      "Best training Accuracy: 186.686\n",
      "Best training Accuracy: 186.686\n",
      "Best training Accuracy: 186.686\n",
      "Best validation Accuracy for d: 103.554\n",
      "Best validation Accuracy for d: 103.554\n",
      "Best validation Accuracy for d: 103.554\n",
      "Best validation Accuracy for d: 103.554\n",
      "Best validation Accuracy for d: 103.554\n",
      "Best validation Accuracy for d: 103.554\n",
      "Best validation Accuracy for d: 103.554\n",
      "Saved weights of the model at epoch: 44\n",
      "Saved weights of the model at epoch: 44\n",
      "Saved weights of the model at epoch: 44\n",
      "Saved weights of the model at epoch: 44\n",
      "Saved weights of the model at epoch: 44\n",
      "Saved weights of the model at epoch: 44\n",
      "Saved weights of the model at epoch: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[32m     38\u001b[39m trainer.train()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practical work/monoloco/monoloco/train/trainer.py:232\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, load, model, debug)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m    231\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.model(inputs)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdic_err\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclst\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28mself\u001b[39m.cout_stats(dic_err[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m], size_eval, clst=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Evaluate performances on different clusters and save statistics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practical work/monoloco/monoloco/train/trainer.py:289\u001b[39m, in \u001b[36mTrainer.compute_stats\u001b[39m\u001b[34m(self, outputs, labels, dic_err, size_eval, clst)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loss_values) == \u001b[32m2\u001b[39m * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tasks)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.tasks):\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     dic_err[\u001b[33m'\u001b[39m\u001b[33msigmas\u001b[39m\u001b[33m'\u001b[39m][i] += \u001b[38;5;28mfloat\u001b[39m(\u001b[43mloss_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m.item()) * rel_frac\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monoloco.monoloco.train import Trainer  # Import the Trainer class directly\n",
    "from monoloco.run import cli  # Import the argument parsing function\n",
    "\n",
    "# Manually define the arguments (similar to the command-line ones)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Arguments for training\n",
    "        self.joints = '/Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json'\n",
    "        self.mode = 'mono'\n",
    "        self.out = '/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_outputtrial.pkl'\n",
    "        self.epochs = 50\n",
    "        self.bs = 8  # Batch size\n",
    "        self.monocular = True\n",
    "        self.dropout = 0.2\n",
    "        self.lr = 0.001\n",
    "        self.sched_step = 10\n",
    "        self.sched_gamma = 0.5\n",
    "        self.hidden_size = 1024\n",
    "        self.n_stage = 3\n",
    "        self.print_loss = True\n",
    "        self.r_seed = 1  # Default random seed\n",
    "        self.no_save = False\n",
    "\n",
    "        # Add missing arguments\n",
    "        self.auto_tune_mtl = True  # Set this to True or False as needed\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Check device and set it to 'mps' or 'cpu'\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the Trainer class and start training\n",
    "trainer = Trainer(args, device)\n",
    "\n",
    "# Run the training\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cf6d9b1-4eda-46aa-bcb9-cdb387b06443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/youssefelsaady/Desktop/Practical work/monoloco')  # Make sure to replace this with the correct path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1aff844c-581a-43aa-83cb-bcfe8e89fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1734616787.927043438.png\n",
      "Processed: 1734616785.289476395.png\n",
      "Processed: 1734616779.947765350.png\n",
      "Processed: 1734616778.879242420.png\n",
      "Processed: 1734616783.686670542.png\n",
      "Processed: 1734616786.457945347.png\n",
      "Processed: 1734616786.724496365.png\n",
      "Processed: 1734616786.558060408.png\n",
      "Processed: 1734616783.887075424.png\n",
      "Processed: 1734616778.011349440.png\n",
      "Processed: 1734616785.456094503.png\n",
      "Processed: 1734616780.114912510.png\n",
      "Processed: 1734616780.815389395.png\n",
      "Processed: 1734616781.883795500.png\n",
      "Processed: 1734616778.745402336.png\n",
      "Processed: 1734616783.319726467.png\n",
      "Processed: 1734616784.721693516.png\n",
      "Processed: 1734616787.626941442.png\n",
      "Processed: 1734616784.054267406.png\n",
      "Processed: 1734616776.775894403.png\n",
      "Processed: 1734616782.952224493.png\n",
      "Processed: 1734616782.217726469.png\n",
      "Processed: 1734616786.157559395.png\n",
      "Processed: 1734616779.179404497.png\n",
      "Processed: 1734616778.311420441.png\n",
      "Processed: 1734616776.074943542.png\n",
      "Processed: 1734616784.555142403.png\n",
      "Processed: 1734616781.182485342.png\n",
      "Processed: 1734616777.242648363.png\n",
      "Processed: 1734616781.683503389.png\n",
      "Processed: 1734616788.527853489.png\n",
      "Processed: 1734616781.383016348.png\n",
      "Processed: 1734616780.649172544.png\n",
      "Processed: 1734616781.516531467.png\n",
      "Processed: 1734616776.642311335.png\n",
      "Processed: 1734616775.940945387.png\n",
      "Processed: 1734616775.774053335.png\n",
      "Processed: 1734616779.780920506.png\n",
      "Processed: 1734616777.543611526.png\n",
      "Processed: 1734616777.844017506.png\n",
      "Processed: 1734616785.823025465.png\n",
      "Processed: 1734616784.922120333.png\n",
      "Processed: 1734616785.623207331.png\n",
      "Processed: 1734616788.394329548.png\n",
      "Processed: 1734616780.982817411.png\n",
      "Processed: 1734616787.158945560.png\n",
      "Processed: 1734616779.613517523.png\n",
      "Processed: 1734616783.152488470.png\n",
      "Processed: 1734616786.290850401.png\n",
      "Processed: 1734616779.346384525.png\n",
      "Processed: 1734616778.579141378.png\n",
      "Processed: 1734616776.942249537.png\n",
      "Processed: 1734616782.418046474.png\n",
      "Processed: 1734616786.858587503.png\n",
      "Processed: 1734616787.760415554.png\n",
      "Processed: 1734616784.388057470.png\n",
      "Processed: 1734616776.508472443.png\n",
      "Processed: 1734616778.445024490.png\n",
      "Processed: 1734616788.060040474.png\n",
      "Processed: 1734616782.786443472.png\n",
      "Processed: 1734616783.519718409.png\n",
      "Processed: 1734616787.025492430.png\n",
      "Processed: 1734616785.088638544.png\n",
      "Processed: 1734616787.326381445.png\n",
      "Processed: 1734616780.280752420.png\n",
      "Processed: 1734616778.144856453.png\n",
      "Processed: 1734616777.076903343.png\n",
      "Processed: 1734616777.710915327.png\n",
      "Processed: 1734616779.012540340.png\n",
      "Processed: 1734616779.479885340.png\n",
      "Processed: 1734616780.448274374.png\n",
      "Processed: 1734616782.050726414.png\n",
      "Processed: 1734616776.374941349.png\n",
      "Processed: 1734616785.990007401.png\n",
      "Processed: 1734616776.207899332.png\n",
      "Processed: 1734616784.220544338.png\n",
      "Processed: 1734616788.228708506.png\n",
      "Processed: 1734616787.459607363.png\n",
      "Processed: 1734616777.410064459.png\n",
      "Processed: 1734616782.584980488.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Paths to your directories\n",
    "image_dir = '/Users/youssefelsaady/Desktop/Practical work/extracted_images/'\n",
    "output_dir = '/Users/youssefelsaady/Desktop/Practical work/Output_of_trained_model_final/'\n",
    "model_path = \"/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_model_final.pth\"  # Make sure this is correct\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through images in the image directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # Full image path\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        # Create output path for the prediction\n",
    "        output_path = os.path.join(output_dir, f\"out_{filename}\")\n",
    "        \n",
    "        # Command to run the model for prediction\n",
    "        command = [\n",
    "            \"python3\", \"-m\", \"monoloco.run\", \"predict\",\n",
    "            image_path,                         # Input image path\n",
    "            \"--mode\", \"mono\",                    # Using mono mode\n",
    "            \"--model\", f\"{model_path}\",          # Path to the trained model\n",
    "            \"--output-directory\", output_dir    # Output directory for predictions\n",
    "        ]\n",
    "        \n",
    "        # Execute the command\n",
    "        try:\n",
    "            result = subprocess.run(command, capture_output=True, text=True)\n",
    "            \n",
    "            # Check if the process was successful\n",
    "            if result.returncode == 0:\n",
    "                print(f\"Processed: {filename}\")\n",
    "            else:\n",
    "                print(f\"Error processing {filename}: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command for {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d28200b5-a5fd-4416-a170-70cb58864057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output3.pkl\n",
      "Device:  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 512 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 50 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 512 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output3.pkl\n",
      ">>> creating model\n",
      ">>> model params: 2.132M\n",
      ">>> loss params: 7\n",
      "0 T::200.9  d:10964  x:4624  y:13517  h:4759  w:8374  l:5210  ori:54.1  V::198.6  d:10908  x:4629  y:13388  h:4769  w:8258  l:5196  ori:51.7  \n",
      "10 T::199.2  d:10935  x:4594  y:13486  h:4728  w:8344  l:5180  ori:53.8  V::198.6  d:10930  x:4642  y:13419  h:4796  w:8282  l:5223  ori:52.4  \n",
      "20 T::199.1  d:10933  x:4591  y:13484  h:4725  w:8340  l:5177  ori:53.8  V::198.4  d:10915  x:4626  y:13397  h:4776  w:8261  l:5202  ori:51.9  \n",
      "30 T::198.9  d:10930  x:4588  y:13481  h:4722  w:8337  l:5174  ori:53.7  V::198.8  d:10916  x:4638  y:13398  h:4776  w:8270  l:5203  ori:51.8  \n",
      "40 T::199.1  d:10933  x:4590  y:13484  h:4725  w:8341  l:5178  ori:53.7  V::197.4  d:10893  x:4598  y:13372  h:4754  w:8235  l:5177  ori:51.9  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Training complete in 4m 18s\n",
      "Training:\n",
      "Training complete in 4m 18s\n",
      "Best training Accuracy: 199.043\n",
      "Best training Accuracy: 199.043\n",
      "Best validation Accuracy for d: 108.665\n",
      "Best validation Accuracy for d: 108.665\n",
      "Saved weights of the model at epoch: 3\n",
      "Saved weights of the model at epoch: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Manually invoke the evaluation method if it doesn't work automatically\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Here we check for a potential missing `evaluate` method or any issues with its execution\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluation method not implemented or not working, skipping.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practical work/monoloco/monoloco/train/trainer.py:232\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, load, model, debug)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m    231\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.model(inputs)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdic_err\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclst\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28mself\u001b[39m.cout_stats(dic_err[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m], size_eval, clst=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Evaluate performances on different clusters and save statistics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Practical work/monoloco/monoloco/train/trainer.py:289\u001b[39m, in \u001b[36mTrainer.compute_stats\u001b[39m\u001b[34m(self, outputs, labels, dic_err, size_eval, clst)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loss_values) == \u001b[32m2\u001b[39m * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.tasks)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.tasks):\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     dic_err[\u001b[33m'\u001b[39m\u001b[33msigmas\u001b[39m\u001b[33m'\u001b[39m][i] += \u001b[38;5;28mfloat\u001b[39m(\u001b[43mloss_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m.item()) * rel_frac\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monoloco.monoloco.train import Trainer  # Import the Trainer class directly\n",
    "from monoloco.run import cli  # Import the argument parsing function\n",
    "\n",
    "# Manually define the arguments (similar to the command-line ones)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Arguments for training\n",
    "        self.joints = '/Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json'\n",
    "        self.mode = 'mono'\n",
    "        self.out = '/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output3.pkl'\n",
    "        self.epochs = 50\n",
    "        self.bs = 8  # Batch size\n",
    "        self.monocular = True\n",
    "        self.dropout = 0.2\n",
    "        self.lr = 0.001\n",
    "        self.sched_step = 10\n",
    "        self.sched_gamma = 0.5\n",
    "        self.hidden_size = 512\n",
    "        self.n_stage = 3\n",
    "        self.print_loss = True\n",
    "        self.r_seed = 1  # Default random seed\n",
    "        self.no_save = False\n",
    "        self.auto_tune_mtl = True  # Set this to True or False as needed\n",
    "\n",
    "        # Adding model name argument for naming the model\n",
    "        self.model_name = 'my_trained_model'  # Default name\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Check device and set it to 'mps' or 'cpu'\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the Trainer class and pass the model name\n",
    "trainer = Trainer(args, device)\n",
    "\n",
    "# Run the training\n",
    "trainer.train()\n",
    "\n",
    "# Manually invoke the evaluation method if it doesn't work automatically\n",
    "# Here we check for a potential missing `evaluate` method or any issues with its execution\n",
    "try:\n",
    "    trainer.evaluate()\n",
    "except AttributeError:\n",
    "    print(\"Evaluation method not implemented or not working, skipping.\")\n",
    "\n",
    "# Alternatively, after training, you can explicitly save the model if evaluate doesn't work.\n",
    "model_path = f\"/path/to/save/{args.model_name}.pth\"\n",
    "torch.save(trainer.model.state_dict(), model_path)\n",
    "print(f\"Model saved as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "068a1d8a-09eb-4a21-a6e2-f5f3948b504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output_final.pkl\n",
      "Device:  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "\n",
      "VERSION: 0.7.4.6\n",
      "\n",
      "INPUT_FILE: /Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json\n",
      "Input file version: lsp_custom\n",
      "Torch version: 2.1.0\n",
      "\n",
      "Training arguments:\n",
      "mode: mono \n",
      "learning rate: 0.001 \n",
      "batch_size: 8\n",
      "epochs: 500 \n",
      "dropout: 0.2 \n",
      "scheduler step: 10 \n",
      "scheduler gamma: 0.5 \n",
      "input_size: 34 \n",
      "output_size: 9 \n",
      "hidden_size: 1024 \n",
      "n_stages: 3 \n",
      " r_seed: 1 \n",
      "lambdas: (1, 1, 1, 1, 1, 1, 1)\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n",
      "Sizes of the dataset: {'train': 1600, 'val': 400}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output_final.pkl\n",
      ">>> creating model\n",
      ">>> model params: 8.458M\n",
      ">>> loss params: 7\n",
      "0 T::189.6  d:10507  x:4196  y:13093  h:4345  w:7929  l:4760  ori:49.0  V::185.2  d:10382  x:4113  y:12917  h:4295  w:7746  l:4703  ori:45.4  \n",
      "10 T::186.8  d:10434  x:4117  y:13014  h:4266  w:7849  l:4679  ori:47.8  V::186.1  d:10395  x:4140  y:12938  h:4311  w:7770  l:4727  ori:45.2  \n",
      "20 T::186.7  d:10431  x:4115  y:13011  h:4265  w:7848  l:4679  ori:47.9  V::186.0  d:10415  x:4144  y:12950  h:4327  w:7780  l:4736  ori:46.0  \n",
      "30 T::186.7  d:10434  x:4119  y:13014  h:4267  w:7850  l:4680  ori:47.9  V::185.1  d:10387  x:4107  y:12917  h:4296  w:7740  l:4697  ori:46.1  \n",
      "40 T::186.7  d:10433  x:4118  y:13014  h:4265  w:7849  l:4679  ori:47.8  V::186.4  d:10425  x:4159  y:12963  h:4338  w:7794  l:4751  ori:45.9  \n",
      "50 T::186.8  d:10438  x:4121  y:13019  h:4269  w:7855  l:4684  ori:47.8  V::185.9  d:10404  x:4135  y:12941  h:4317  w:7771  l:4727  ori:45.5  \n",
      "60 T::186.7  d:10434  x:4119  y:13015  h:4268  w:7852  l:4680  ori:47.9  V::185.9  d:10421  x:4136  y:12949  h:4328  w:7773  l:4731  ori:46.9  \n",
      "70 T::186.8  d:10433  x:4117  y:13014  h:4266  w:7849  l:4679  ori:47.9  V::185.8  d:10402  x:4133  y:12938  h:4315  w:7767  l:4724  ori:45.6  \n",
      "80 T::186.9  d:10433  x:4117  y:13014  h:4266  w:7849  l:4679  ori:47.9  V::186.1  d:10408  x:4141  y:12945  h:4322  w:7774  l:4732  ori:45.7  \n",
      "90 T::186.8  d:10435  x:4118  y:13015  h:4267  w:7851  l:4680  ori:47.9  V::185.8  d:10398  x:4135  y:12936  h:4312  w:7766  l:4724  ori:45.6  \n",
      "100 T::186.8  d:10434  x:4118  y:13013  h:4265  w:7849  l:4680  ori:47.9  V::184.8  d:10375  x:4097  y:12906  h:4284  w:7730  l:4686  ori:45.8  \n",
      "110 T::186.7  d:10435  x:4118  y:13015  h:4268  w:7851  l:4681  ori:47.9  V::186.0  d:10416  x:4140  y:12951  h:4327  w:7775  l:4732  ori:46.5  \n",
      "120 T::186.7  d:10434  x:4118  y:13015  h:4266  w:7850  l:4680  ori:47.9  V::185.6  d:10387  x:4123  y:12925  h:4300  w:7755  l:4712  ori:45.4  \n",
      "130 T::186.7  d:10431  x:4115  y:13011  h:4264  w:7846  l:4676  ori:47.8  V::187.4  d:10472  x:4196  y:13006  h:4381  w:7835  l:4794  ori:47.0  \n",
      "140 T::186.7  d:10438  x:4121  y:13017  h:4270  w:7853  l:4683  ori:47.8  V::186.2  d:10426  x:4150  y:12959  h:4337  w:7786  l:4744  ori:46.3  \n",
      "150 T::186.8  d:10434  x:4118  y:13016  h:4267  w:7850  l:4681  ori:47.9  V::187.1  d:10453  x:4183  y:12991  h:4366  w:7820  l:4778  ori:46.6  \n",
      "160 T::186.7  d:10432  x:4116  y:13013  h:4264  w:7847  l:4678  ori:47.8  V::185.7  d:10394  x:4126  y:12932  h:4308  w:7759  l:4717  ori:45.4  \n",
      "170 T::186.6  d:10433  x:4115  y:13013  h:4265  w:7850  l:4679  ori:47.8  V::186.4  d:10425  x:4151  y:12961  h:4337  w:7788  l:4745  ori:46.1  \n",
      "180 T::186.6  d:10432  x:4113  y:13012  h:4264  w:7847  l:4678  ori:47.8  V::186.5  d:10422  x:4157  y:12962  h:4336  w:7792  l:4748  ori:45.7  \n",
      "190 T::186.7  d:10434  x:4119  y:13016  h:4267  w:7851  l:4681  ori:47.8  V::186.7  d:10428  x:4162  y:12968  h:4342  w:7797  l:4755  ori:45.9  \n",
      "200 T::186.7  d:10437  x:4121  y:13018  h:4269  w:7854  l:4684  ori:47.8  V::186.9  d:10438  x:4172  y:12978  h:4351  w:7809  l:4766  ori:46.1  \n",
      "210 T::186.8  d:10433  x:4116  y:13013  h:4265  w:7849  l:4679  ori:47.8  V::185.7  d:10407  x:4129  y:12940  h:4317  w:7764  l:4721  ori:46.1  \n",
      "220 T::186.7  d:10431  x:4116  y:13012  h:4264  w:7848  l:4677  ori:47.8  V::185.3  d:10379  x:4112  y:12916  h:4293  w:7744  l:4700  ori:45.5  \n",
      "230 T::186.9  d:10439  x:4123  y:13019  h:4271  w:7855  l:4685  ori:47.9  V::186.4  d:10424  x:4155  y:12962  h:4337  w:7790  l:4748  ori:45.9  \n",
      "240 T::186.7  d:10432  x:4117  y:13014  h:4266  w:7848  l:4678  ori:47.8  V::186.5  d:10436  x:4159  y:12968  h:4347  w:7798  l:4755  ori:46.6  \n",
      "250 T::186.7  d:10431  x:4113  y:13010  h:4263  w:7847  l:4676  ori:47.9  V::185.5  d:10400  x:4124  y:12933  h:4312  w:7759  l:4716  ori:46.2  \n",
      "260 T::186.7  d:10432  x:4114  y:13011  h:4264  w:7849  l:4677  ori:47.8  V::186.3  d:10423  x:4149  y:12959  h:4334  w:7787  l:4743  ori:46.0  \n",
      "270 T::186.7  d:10435  x:4119  y:13015  h:4267  w:7851  l:4681  ori:47.8  V::184.5  d:10359  x:4085  y:12890  h:4270  w:7717  l:4673  ori:45.4  \n",
      "280 T::186.7  d:10437  x:4121  y:13017  h:4269  w:7853  l:4682  ori:47.8  V::185.8  d:10398  x:4130  y:12936  h:4312  w:7764  l:4721  ori:45.6  \n",
      "290 T::186.7  d:10435  x:4118  y:13014  h:4268  w:7851  l:4680  ori:47.8  V::186.6  d:10419  x:4157  y:12961  h:4334  w:7793  l:4749  ori:45.5  \n",
      "300 T::186.7  d:10431  x:4115  y:13012  h:4266  w:7848  l:4677  ori:47.8  V::186.1  d:10409  x:4143  y:12947  h:4323  w:7777  l:4733  ori:45.6  \n",
      "310 T::186.8  d:10435  x:4119  y:13017  h:4268  w:7852  l:4681  ori:47.8  V::186.3  d:10420  x:4152  y:12958  h:4333  w:7786  l:4743  ori:46.0  \n",
      "320 T::186.6  d:10431  x:4114  y:13011  h:4262  w:7846  l:4675  ori:47.8  V::186.4  d:10431  x:4159  y:12967  h:4344  w:7795  l:4753  ori:46.4  \n",
      "330 T::186.9  d:10434  x:4118  y:13014  h:4267  w:7850  l:4681  ori:47.8  V::186.5  d:10432  x:4157  y:12968  h:4343  w:7795  l:4751  ori:46.3  \n",
      "340 T::186.7  d:10432  x:4115  y:13012  h:4264  w:7849  l:4678  ori:47.8  V::187.1  d:10429  x:4174  y:12974  h:4346  w:7808  l:4765  ori:45.4  \n",
      "350 T::186.7  d:10433  x:4117  y:13014  h:4266  w:7851  l:4680  ori:47.8  V::186.7  d:10443  x:4161  y:12977  h:4352  w:7798  l:4755  ori:47.1  \n",
      "360 T::186.7  d:10435  x:4119  y:13013  h:4266  w:7850  l:4680  ori:47.8  V::186.2  d:10414  x:4146  y:12952  h:4327  w:7781  l:4738  ori:46.1  \n",
      "370 T::186.8  d:10435  x:4119  y:13015  h:4267  w:7851  l:4681  ori:47.9  V::186.8  d:10437  x:4170  y:12977  h:4350  w:7807  l:4764  ori:46.1  \n",
      "380 T::186.7  d:10437  x:4120  y:13016  h:4269  w:7853  l:4681  ori:47.8  V::185.5  d:10393  x:4116  y:12926  h:4304  w:7751  l:4709  ori:45.7  \n",
      "390 T::187.0  d:10438  x:4121  y:13019  h:4271  w:7856  l:4685  ori:47.9  V::185.1  d:10363  x:4101  y:12901  h:4278  w:7731  l:4688  ori:44.8  \n",
      "400 T::186.7  d:10432  x:4117  y:13014  h:4264  w:7848  l:4678  ori:47.8  V::186.8  d:10430  x:4171  y:12972  h:4345  w:7805  l:4763  ori:45.7  \n",
      "410 T::186.7  d:10431  x:4115  y:13011  h:4264  w:7846  l:4678  ori:47.8  V::186.5  d:10434  x:4160  y:12969  h:4345  w:7795  l:4753  ori:46.6  \n",
      "420 T::186.6  d:10430  x:4113  y:13009  h:4263  w:7846  l:4676  ori:47.8  V::186.4  d:10411  x:4154  y:12951  h:4327  w:7787  l:4745  ori:45.4  \n",
      "430 T::186.8  d:10435  x:4118  y:13016  h:4268  w:7850  l:4681  ori:47.8  V::185.4  d:10381  x:4118  y:12920  h:4296  w:7750  l:4708  ori:45.3  \n",
      "440 T::186.7  d:10435  x:4117  y:13016  h:4267  w:7850  l:4682  ori:47.9  V::185.9  d:10411  x:4137  y:12945  h:4322  w:7771  l:4727  ori:46.1  \n",
      "450 T::186.8  d:10436  x:4119  y:13017  h:4269  w:7853  l:4683  ori:47.9  V::185.5  d:10391  x:4121  y:12926  h:4303  w:7755  l:4712  ori:45.6  \n",
      "460 T::186.9  d:10437  x:4119  y:13017  h:4269  w:7852  l:4683  ori:47.9  V::186.3  d:10425  x:4153  y:12960  h:4336  w:7789  l:4745  ori:46.1  \n",
      "470 T::186.7  d:10431  x:4114  y:13010  h:4263  w:7848  l:4677  ori:47.8  V::184.5  d:10363  x:4078  y:12891  h:4271  w:7711  l:4667  ori:45.6  \n",
      "480 T::186.8  d:10436  x:4119  y:13015  h:4268  w:7852  l:4683  ori:47.9  V::187.0  d:10449  x:4179  y:12986  h:4361  w:7817  l:4774  ori:46.2  \n",
      "490 T::186.8  d:10436  x:4119  y:13016  h:4267  w:7851  l:4682  ori:47.9  V::186.6  d:10431  x:4161  y:12970  h:4343  w:7799  l:4756  ori:45.9  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Training:\n",
      "Training complete in 53m 14s\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best training Accuracy: 186.742\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Best validation Accuracy for d: 103.284\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n",
      "Saved weights of the model at epoch: 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Model saved to /Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monoloco.monoloco.train import Trainer  # Import the Trainer class directly\n",
    "from monoloco.run import cli  # Import the argument parsing function\n",
    "\n",
    "# Manually define the arguments (similar to the command-line ones)\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Arguments for training\n",
    "        self.joints = '/Users/youssefelsaady/Desktop/Practical work/LSP Dataset/joints_with_images2.json'\n",
    "        self.mode = 'mono'\n",
    "        self.out = '/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_output_final.pkl'\n",
    "        self.epochs = 500\n",
    "        self.bs = 8  # Batch size\n",
    "        self.monocular = True\n",
    "        self.dropout = 0.2\n",
    "        self.lr = 0.001\n",
    "        self.sched_step = 10\n",
    "        self.sched_gamma = 0.5\n",
    "        self.hidden_size = 1024\n",
    "        self.n_stage = 3\n",
    "        self.print_loss = True\n",
    "        self.r_seed = 1  # Default random seed\n",
    "        self.no_save = False\n",
    "        self.auto_tune_mtl = True  # Set this to True or False as needed\n",
    "        self.model_name = 'my_trained_model_final'  # Default name\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Check device and set it to 'mps' or 'cpu'\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the Trainer class and pass the model name\n",
    "trainer = Trainer(args, device)\n",
    "\n",
    "# Run the training\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# Alternatively, after training, you can explicitly save the model if evaluate doesn't work.\n",
    "model_path = \"/Users/youssefelsaady/Desktop/Practical work/Train_output/monoloco_lsp_model_final.pth\"\n",
    "torch.save(trainer.model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc763822-7392-4a71-894e-a4ecb1292598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ros_env)",
   "language": "python",
   "name": "ros_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
